Metadata-Version: 2.4
Name: proxa
Version: 0.1.0
Summary: Un autoscaler inteligente para servidores WSGI/ASGI.
Author-email: Jearel Alcantara <jeasoft@gmail.com>
Project-URL: Homepage, https://github.com/jesuslarag/proxa
Project-URL: Bug Tracker, https://github.com/jesuslarag/proxa/issues
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Topic :: System :: Monitoring
Classifier: Topic :: Software Development :: Libraries :: Application Frameworks
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: click>=8.0
Requires-Dist: psutil>=7.0.0
Requires-Dist: anyio>=4.0
Requires-Dist: msgspec>=0.19
Requires-Dist: tomli>=2.0.0; python_version < "3.11"

# Proxa

An intelligent autoscaler for ASGI/WSGI servers with built-in health monitoring.

## Features

- Automatic worker scaling based on CPU and memory metrics
- Support for multiple ASGI/WSGI servers:
  - Uvicorn
  - Hypercorn
  - Granian
- Built-in health monitoring
- Configurable via CLI or TOML files
- Graceful worker management
- Real-time metrics collection

## Installation

```bash
pip install proxa
```

## Quick Start
Run your ASGI application with automatic scaling:

With health monitoring enabled:
```
proxa run --server uvicorn --app myapp:app --workers 2
```

## Configuration
### Via TOML File
Create a proxa.toml :

```toml
server = "uvicorn"
app = "myapp:app"
workers = 2
min_workers = 1
max_workers = 5
max_cpu = 80.0
max_mem = 512  # MB
enable_health = true
health_host = "127.0.0.1"
health_port = 9000
 ```

Run with config file:

```bash
proxa run -c proxa.toml
 ```
